#!/bin/bash

# Submit Spark Job Script per Portfolio Risk Analyzer
# Questo script facilita il lancio del job Spark nel cluster

set -e

echo "üöÄ Portfolio Risk Analyzer - Spark Job Submitter"
echo "================================================"

# Configurazioni
SPARK_MASTER="spark://spark-master:7077"
APP_NAME="Portfolio Risk Analyzer"
MAIN_FILE="/opt/bitnami/spark/jobs/stream_processor.py"
DRIVER_MEMORY="1g"
EXECUTOR_MEMORY="1g"
EXECUTOR_CORES="1"

# Verifica che Spark sia in esecuzione
echo "üîç Verifica stato Spark Master..."
if ! curl -s http://localhost:8081 > /dev/null; then
    echo "‚ùå Spark Master non raggiungibile su http://localhost:8081"
    echo "üí° Assicurati che Docker Compose sia in esecuzione:"
    echo "   docker compose up -d spark-master spark-worker"
    exit 1
fi

echo "‚úÖ Spark Master raggiungibile"

# Verifica che il file Python esista
if [ ! -f "scripts/spark/stream_processor.py" ]; then
    echo "‚ùå File stream_processor.py non trovato in scripts/spark/"
    echo "üí° Assicurati che il file sia presente e che tu sia nella directory corretta"
    exit 1
fi

echo "‚úÖ Script Spark trovato"

# Verifica che Kafka sia in esecuzione
echo "üîç Verifica stato Kafka..."
if ! docker compose exec -T kafka kafka-topics --bootstrap-server localhost:9092 --list &>/dev/null; then
    echo "‚ùå Kafka non raggiungibile"
    echo "üí° Assicurati che Kafka sia in esecuzione:"
    echo "   docker compose up -d kafka"
    exit 1
fi

echo "‚úÖ Kafka raggiungibile"

# Lista i topic Kafka per debug
echo "üìã Topic Kafka disponibili:"
docker compose exec -T kafka kafka-topics --bootstrap-server localhost:9092 --list | sed 's/^/   /'

echo "‚úÖ Script Spark trovato"

# Submit del job
echo "üöÄ Lancio del job Spark..."
echo "üìä Parametri:"
echo "   - Master: $SPARK_MASTER"
echo "   - App: $APP_NAME"
echo "   - Driver Memory: $DRIVER_MEMORY"
echo "   - Executor Memory: $EXECUTOR_MEMORY"
echo "   - Executor Cores: $EXECUTOR_CORES"
echo ""
echo "üí° Per fermare il job, usa Ctrl+C"
echo ""

docker compose exec spark-master spark-submit \
    --master "$SPARK_MASTER" \
    --name "$APP_NAME" \
    --driver-memory "$DRIVER_MEMORY" \
    --executor-memory "$EXECUTOR_MEMORY" \
    --executor-cores "$EXECUTOR_CORES" \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
    --conf spark.sql.streaming.forceDeleteTempCheckpointLocation=true \
    --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
    --conf spark.executor.extraJavaOptions="-XX:+UseG1GC" \
    --conf spark.driver.extraJavaOptions="-XX:+UseG1GC" \
    --conf spark.network.timeout=300s \
    --conf spark.executor.heartbeatInterval=60s \
    "$MAIN_FILE"

exit_code=$?

echo ""
if [ $exit_code -eq 0 ]; then
    echo "üéØ Job completato con successo!"
else
    echo "‚ùå Job terminato con errore (exit code: $exit_code)"
    echo ""
    echo "üîß Possibili cause:"
    echo "   - Problemi di connessione Kafka"
    echo "   - Errori nel codice Python"
    echo "   - Risorse insufficienti"
    echo ""
    echo "üí° Controlla i log per dettagli:"
    echo "   docker compose logs spark-master | tail -20"
    echo "   docker compose logs spark-worker | tail -20"
fi

echo ""
echo "üìä Per monitorare i job Spark:"
echo "   - Spark Master UI: http://localhost:8081"
echo "   - Spark Worker UI: http://localhost:8082"
echo "   - Kafka UI: http://localhost:8080"